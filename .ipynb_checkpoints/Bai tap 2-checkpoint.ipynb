{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load dữ liệu voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice=pd.read_csv('voice.csv')\n",
    "voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "39e154cb54356acfac8c2edd1e565b42edf0b502",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.057126</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>0.140456</td>\n",
       "      <td>0.224765</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>3.140168</td>\n",
       "      <td>36.568461</td>\n",
       "      <td>0.895127</td>\n",
       "      <td>0.408216</td>\n",
       "      <td>0.165282</td>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.142807</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.258842</td>\n",
       "      <td>0.829211</td>\n",
       "      <td>0.052647</td>\n",
       "      <td>5.047277</td>\n",
       "      <td>4.994630</td>\n",
       "      <td>0.173752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.036360</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.042783</td>\n",
       "      <td>4.240529</td>\n",
       "      <td>134.928661</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.177521</td>\n",
       "      <td>0.077203</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>0.525205</td>\n",
       "      <td>0.063299</td>\n",
       "      <td>3.521157</td>\n",
       "      <td>3.520039</td>\n",
       "      <td>0.119454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.018363</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.042946</td>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.141735</td>\n",
       "      <td>2.068455</td>\n",
       "      <td>0.738651</td>\n",
       "      <td>0.036876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.055565</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.041954</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.111087</td>\n",
       "      <td>0.208747</td>\n",
       "      <td>0.042560</td>\n",
       "      <td>1.649569</td>\n",
       "      <td>5.669547</td>\n",
       "      <td>0.861811</td>\n",
       "      <td>0.258041</td>\n",
       "      <td>0.118016</td>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.116998</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.419828</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.070312</td>\n",
       "      <td>2.044922</td>\n",
       "      <td>0.099766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.059155</td>\n",
       "      <td>0.190032</td>\n",
       "      <td>0.140286</td>\n",
       "      <td>0.225684</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>2.197101</td>\n",
       "      <td>8.318463</td>\n",
       "      <td>0.901767</td>\n",
       "      <td>0.396335</td>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.140519</td>\n",
       "      <td>0.046110</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.765795</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>4.992188</td>\n",
       "      <td>4.945312</td>\n",
       "      <td>0.139357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.067020</td>\n",
       "      <td>0.210618</td>\n",
       "      <td>0.175939</td>\n",
       "      <td>0.243660</td>\n",
       "      <td>0.114175</td>\n",
       "      <td>2.931694</td>\n",
       "      <td>13.648905</td>\n",
       "      <td>0.928713</td>\n",
       "      <td>0.533676</td>\n",
       "      <td>0.221104</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.169581</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>0.277457</td>\n",
       "      <td>1.177166</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>7.007812</td>\n",
       "      <td>6.992188</td>\n",
       "      <td>0.209183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.115273</td>\n",
       "      <td>0.261224</td>\n",
       "      <td>0.247347</td>\n",
       "      <td>0.273469</td>\n",
       "      <td>0.252225</td>\n",
       "      <td>34.725453</td>\n",
       "      <td>1309.612887</td>\n",
       "      <td>0.981997</td>\n",
       "      <td>0.842936</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.237636</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.279114</td>\n",
       "      <td>2.957682</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>21.867188</td>\n",
       "      <td>21.843750</td>\n",
       "      <td>0.932374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanfreq           sd       median          Q25          Q75  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.180907     0.057126     0.185621     0.140456     0.224765   \n",
       "std       0.029918     0.016652     0.036360     0.048680     0.023639   \n",
       "min       0.039363     0.018363     0.010975     0.000229     0.042946   \n",
       "25%       0.163662     0.041954     0.169593     0.111087     0.208747   \n",
       "50%       0.184838     0.059155     0.190032     0.140286     0.225684   \n",
       "75%       0.199146     0.067020     0.210618     0.175939     0.243660   \n",
       "max       0.251124     0.115273     0.261224     0.247347     0.273469   \n",
       "\n",
       "               IQR         skew         kurt       sp.ent          sfm  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.084309     3.140168    36.568461     0.895127     0.408216   \n",
       "std       0.042783     4.240529   134.928661     0.044980     0.177521   \n",
       "min       0.014558     0.141735     2.068455     0.738651     0.036876   \n",
       "25%       0.042560     1.649569     5.669547     0.861811     0.258041   \n",
       "50%       0.094280     2.197101     8.318463     0.901767     0.396335   \n",
       "75%       0.114175     2.931694    13.648905     0.928713     0.533676   \n",
       "max       0.252225    34.725453  1309.612887     0.981997     0.842936   \n",
       "\n",
       "              mode     centroid      meanfun       minfun       maxfun  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.165282     0.180907     0.142807     0.036802     0.258842   \n",
       "std       0.077203     0.029918     0.032304     0.019220     0.030077   \n",
       "min       0.000000     0.039363     0.055565     0.009775     0.103093   \n",
       "25%       0.118016     0.163662     0.116998     0.018223     0.253968   \n",
       "50%       0.186599     0.184838     0.140519     0.046110     0.271186   \n",
       "75%       0.221104     0.199146     0.169581     0.047904     0.277457   \n",
       "max       0.280000     0.251124     0.237636     0.204082     0.279114   \n",
       "\n",
       "           meandom       mindom       maxdom      dfrange      modindx  \n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  \n",
       "mean      0.829211     0.052647     5.047277     4.994630     0.173752  \n",
       "std       0.525205     0.063299     3.521157     3.520039     0.119454  \n",
       "min       0.007812     0.004883     0.007812     0.000000     0.000000  \n",
       "25%       0.419828     0.007812     2.070312     2.044922     0.099766  \n",
       "50%       0.765795     0.023438     4.992188     4.945312     0.139357  \n",
       "75%       1.177166     0.070312     7.007812     6.992188     0.209183  \n",
       "max       2.957682     0.458984    21.867188    21.843750     0.932374  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5966f35aea13387065d525aabdcceaa809e08eeb"
   },
   "source": [
    "## II. Chuẩn hóa dữ liệu đầu vào và sử dụng biến giả cho nhãn labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "523e9d19559457ef6269c8ff9f68a1fd15a6a3fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "voice[\"label\"] = le.fit_transform(voice[\"label\"])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "dacdfb24e542b09bfacbf9dd9dfe497b630c02d1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.473409</td>\n",
       "      <td>0.084125</td>\n",
       "      <td>0.060063</td>\n",
       "      <td>0.204956</td>\n",
       "      <td>0.254828</td>\n",
       "      <td>0.367853</td>\n",
       "      <td>0.208279</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.564526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.157706</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.981526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.505075</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.077635</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.246961</td>\n",
       "      <td>0.644279</td>\n",
       "      <td>0.483766</td>\n",
       "      <td>0.630964</td>\n",
       "      <td>0.591578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.287642</td>\n",
       "      <td>0.031140</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.056449</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179222</td>\n",
       "      <td>0.675536</td>\n",
       "      <td>0.102873</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.385912</td>\n",
       "      <td>0.457148</td>\n",
       "      <td>0.885255</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.442738</td>\n",
       "      <td>0.548382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179222</td>\n",
       "      <td>0.236945</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>0.954963</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.049885</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.554611</td>\n",
       "      <td>0.587559</td>\n",
       "      <td>0.389906</td>\n",
       "      <td>0.715802</td>\n",
       "      <td>0.407358</td>\n",
       "      <td>0.031549</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.923261</td>\n",
       "      <td>0.856457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.183442</td>\n",
       "      <td>0.041287</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.065659</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.265043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452195</td>\n",
       "      <td>0.627209</td>\n",
       "      <td>0.454272</td>\n",
       "      <td>0.317627</td>\n",
       "      <td>0.707515</td>\n",
       "      <td>0.474474</td>\n",
       "      <td>0.027742</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.958736</td>\n",
       "      <td>0.926348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452195</td>\n",
       "      <td>0.279190</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.929285</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.250536</td>\n",
       "      <td>0.250715</td>\n",
       "      <td>0.223380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "0  0.096419  0.473409  0.084125  0.060063  0.204956  0.254828  0.367853   \n",
       "1  0.125828  0.505075  0.116900  0.077635  0.215683  0.246961  0.644279   \n",
       "2  0.179222  0.675536  0.102873  0.034284  0.385912  0.457148  0.885255   \n",
       "3  0.528261  0.554611  0.587559  0.389906  0.715802  0.407358  0.031549   \n",
       "4  0.452195  0.627209  0.454272  0.317627  0.707515  0.474474  0.027742   \n",
       "\n",
       "       kurt    sp.ent       sfm  ...  centroid   meanfun    minfun    maxfun  \\\n",
       "0  0.208279  0.635798  0.564526  ...  0.096419  0.157706  0.030501  0.981526   \n",
       "1  0.483766  0.630964  0.591578  ...  0.125828  0.287642  0.031140  0.834600   \n",
       "2  0.782275  0.442738  0.548382  ...  0.179222  0.236945  0.030264  0.954963   \n",
       "3  0.001613  0.923261  0.856457  ...  0.528261  0.183442  0.041287  0.834600   \n",
       "4  0.001732  0.958736  0.926348  ...  0.452195  0.279190  0.036829  0.929285   \n",
       "\n",
       "    meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.000000  0.006452  0.000000  0.000000  0.000000    1.0  \n",
       "1  0.000407  0.006452  0.002144  0.002146  0.056449    1.0  \n",
       "2  0.000060  0.006452  0.000357  0.000358  0.049885    1.0  \n",
       "3  0.065659  0.006452  0.025375  0.025393  0.265043    1.0  \n",
       "4  0.238994  0.006452  0.250536  0.250715  0.223380    1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice[:]=preprocessing.MinMaxScaler().fit_transform(voice)\n",
    "voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.668412</td>\n",
       "      <td>0.399987</td>\n",
       "      <td>0.697887</td>\n",
       "      <td>0.567448</td>\n",
       "      <td>0.788722</td>\n",
       "      <td>0.293484</td>\n",
       "      <td>0.086701</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>0.643020</td>\n",
       "      <td>0.460686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668412</td>\n",
       "      <td>0.479161</td>\n",
       "      <td>0.139093</td>\n",
       "      <td>0.884834</td>\n",
       "      <td>0.278452</td>\n",
       "      <td>0.105184</td>\n",
       "      <td>0.230540</td>\n",
       "      <td>0.228653</td>\n",
       "      <td>0.186354</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.171832</td>\n",
       "      <td>0.145295</td>\n",
       "      <td>0.196990</td>\n",
       "      <td>0.102546</td>\n",
       "      <td>0.180012</td>\n",
       "      <td>0.122616</td>\n",
       "      <td>0.103192</td>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.220233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.177428</td>\n",
       "      <td>0.098916</td>\n",
       "      <td>0.170873</td>\n",
       "      <td>0.178043</td>\n",
       "      <td>0.139395</td>\n",
       "      <td>0.161082</td>\n",
       "      <td>0.161146</td>\n",
       "      <td>0.128119</td>\n",
       "      <td>0.500079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.586978</td>\n",
       "      <td>0.243425</td>\n",
       "      <td>0.633838</td>\n",
       "      <td>0.448602</td>\n",
       "      <td>0.719235</td>\n",
       "      <td>0.117820</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.506112</td>\n",
       "      <td>0.274377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586978</td>\n",
       "      <td>0.337413</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.857144</td>\n",
       "      <td>0.139672</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.094353</td>\n",
       "      <td>0.093616</td>\n",
       "      <td>0.107002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.686980</td>\n",
       "      <td>0.420925</td>\n",
       "      <td>0.715516</td>\n",
       "      <td>0.566764</td>\n",
       "      <td>0.792710</td>\n",
       "      <td>0.335436</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.670306</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686980</td>\n",
       "      <td>0.466594</td>\n",
       "      <td>0.186995</td>\n",
       "      <td>0.954963</td>\n",
       "      <td>0.256955</td>\n",
       "      <td>0.040860</td>\n",
       "      <td>0.228020</td>\n",
       "      <td>0.226395</td>\n",
       "      <td>0.149465</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.502086</td>\n",
       "      <td>0.797777</td>\n",
       "      <td>0.711036</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.419146</td>\n",
       "      <td>0.080673</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.781040</td>\n",
       "      <td>0.616331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.626213</td>\n",
       "      <td>0.196231</td>\n",
       "      <td>0.990585</td>\n",
       "      <td>0.396408</td>\n",
       "      <td>0.144086</td>\n",
       "      <td>0.320229</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>0.224355</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanfreq           sd       median          Q25          Q75  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.668412     0.399987     0.697887     0.567448     0.788722   \n",
       "std       0.141282     0.171832     0.145295     0.196990     0.102546   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.586978     0.243425     0.633838     0.448602     0.719235   \n",
       "50%       0.686980     0.420925     0.715516     0.566764     0.792710   \n",
       "75%       0.754545     0.502086     0.797777     0.711036     0.870690   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               IQR         skew         kurt       sp.ent          sfm  ...  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  ...   \n",
       "mean      0.293484     0.086701     0.026385     0.643020     0.460686  ...   \n",
       "std       0.180012     0.122616     0.103192     0.184838     0.220233  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.117820     0.043600     0.002754     0.506112     0.274377  ...   \n",
       "50%       0.335436     0.059432     0.004780     0.670306     0.445946  ...   \n",
       "75%       0.419146     0.080673     0.008857     0.781040     0.616331  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "          centroid      meanfun       minfun       maxfun      meandom  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.668412     0.479161     0.139093     0.884834     0.278452   \n",
       "std       0.141282     0.177428     0.098916     0.170873     0.178043   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.586978     0.337413     0.043478     0.857144     0.139672   \n",
       "50%       0.686980     0.466594     0.186995     0.954963     0.256955   \n",
       "75%       0.754545     0.626213     0.196231     0.990585     0.396408   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            mindom       maxdom      dfrange      modindx        label  \n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  \n",
       "mean      0.105184     0.230540     0.228653     0.186354     0.500000  \n",
       "std       0.139395     0.161082     0.161146     0.128119     0.500079  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.006452     0.094353     0.093616     0.107002     0.000000  \n",
       "50%       0.040860     0.228020     0.226395     0.149465     0.500000  \n",
       "75%       0.144086     0.320229     0.320100     0.224355     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "01c6142330ed1ac21db52dd832e8d14b4a51ec91"
   },
   "outputs": [],
   "source": [
    "X = voice.iloc[:, :-1]\n",
    "y = voice[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 20)\n",
      "(3168,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Các hàm và thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['female', 'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cost_curve(cost_values):\n",
    "    plt.plot(cost_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conclusion(model, cost=None):\n",
    "    start_time = time.time()\n",
    "    model.fit(X,y)\n",
    "    total_time = time.time() - start_time\n",
    "    y_pred=model.predict(X)\n",
    "    y_predll = (y_pred >= 0.5).astype(int)\n",
    "    if cost is None: cost = model.cost\n",
    "    print(classification_report(y, y_predll, target_names=target_names, digits=4))\n",
    "    print(\"===================\")\n",
    "    print(\"Mean loss: \", cost(y, y_pred))\n",
    "    print(\"Time for fitting: \", total_time)\n",
    "    print(\"===================\")\n",
    "    if hasattr(model, \"cost_values\"):\n",
    "        draw_cost_curve(model.cost_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Sử dụng phương pháp tối ưu Stochastic Average Gradient Descent từ thư viện Scikit-learn cho mô hình Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "19d364d29be43bc856b31f0ddec1d5a50a88e2c5"
   },
   "outputs": [],
   "source": [
    "model = SKLogisticRegression(penalty='none', tol=0.0001, solver='lbfgs', max_iter=2000, verbose=0, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9771    0.9716    0.9744      1584\n",
      "        male     0.9718    0.9773    0.9745      1584\n",
      "\n",
      "    accuracy                         0.9744      3168\n",
      "   macro avg     0.9744    0.9744    0.9744      3168\n",
      "weighted avg     0.9744    0.9744    0.9744      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.8831050725606462\n",
      "Time for fitting:  0.08184957504272461\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "conclusion(model, log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Tự xây dựng các thuật toán tối ưu Gradient Descent, Stochastic Gradient Descent và Mini Batch Gradient Descent cho mô hình Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.e**(-z))\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, optimizer, step_size, steps=1000):\n",
    "        self.optimizer = optimizer\n",
    "        self.step_size = step_size\n",
    "        self.steps = steps\n",
    "        self.params = None\n",
    "        self.cost_values = list()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "        y = np.expand_dims(y, axis=1)\n",
    "        self.params = self.optimizer(X, y, self.step_size, self.steps, self.gradient, self.cost, self.cost_values)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "        y_pred = sigmoid(np.dot(X, self.params))\n",
    "        return np.squeeze(y_pred, axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def gradient(X, y_pred, y):\n",
    "        return 1/ y.shape[0] * np.dot(X.transpose(), (y_pred - y))\n",
    "\n",
    "    @staticmethod\n",
    "    def cost(y, y_pred):\n",
    "        return -1/y.shape[0] * np.squeeze(np.dot(y.transpose(), np.log(y_pred)) + np.dot((1 - y).transpose(), np.log(1 - y_pred)))[()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    step_numb = 0\n",
    "    while step_numb < steps:\n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        grad = gradient(X, y_pred, y)\n",
    "        params -= step_size * grad\n",
    "        cost_value = logreg_cost(y, y_pred)\n",
    "        cost_values.append(cost_value)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9771    0.9716    0.9744      1584\n",
      "        male     0.9718    0.9773    0.9745      1584\n",
      "\n",
      "    accuracy                         0.9744      3168\n",
      "   macro avg     0.9744    0.9744    0.9744      3168\n",
      "weighted avg     0.9744    0.9744    0.9744      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.08822844753809087\n",
      "Time for fitting:  0.6750204563140869\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_gd = LogisticRegression(gradient_descent, 10, 2000)\n",
    "conclusion(logreg_with_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochactis Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values):\n",
    "    N = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "#     params = np.random.randn(d, 1)\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    step_numb = 0\n",
    "    \n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    cost_values.append(logreg_cost(y, y_pred))\n",
    "    \n",
    "    check_w_after = 5\n",
    "    tol = 1e-3\n",
    "    while step_numb < steps:\n",
    "        # shuffle data after every step\n",
    "        shuffled_idxs = np.random.permutation(N)\n",
    "        for i in shuffled_idxs:\n",
    "            curr_X = np.expand_dims(X[i], axis=0)\n",
    "            curr_y = y[i]\n",
    "            curr_y_pred = sigmoid(np.dot(curr_X, params))\n",
    "            \n",
    "            # calculate gradient with current datapoint\n",
    "            grad = gradient(curr_X, curr_y_pred, curr_y)\n",
    "            \n",
    "            # update params\n",
    "            params -= step_size * grad\n",
    "            \n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        cost_value = logreg_cost(y, y_pred)\n",
    "        \n",
    "        cost_values.append(cost_value)\n",
    "        \n",
    "        # stop using tolerance criteria\n",
    "        if step_numb % check_w_after == 0 and cost_value < tol: \n",
    "            print(\"Total steps: \", step_numb)\n",
    "            break\n",
    "            \n",
    "        # step size decays\n",
    "        step_size /= 2    \n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9774    0.9558    0.9665      1584\n",
      "        male     0.9568    0.9779    0.9672      1584\n",
      "\n",
      "    accuracy                         0.9669      3168\n",
      "   macro avg     0.9671    0.9669    0.9669      3168\n",
      "weighted avg     0.9671    0.9669    0.9669      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.15156294191512318\n",
      "Time for fitting:  5.83226203918457\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_sgd = LogisticRegression(stochastic_gradient_descent, 10**-1, 50)\n",
    "conclusion(logreg_with_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values, batch_size=64):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    number_of_batches = y.shape[0] // batch_size + (0 if y.shape[0] % batch_size == 0 else 1)\n",
    "    print(\"Number of batches: \", number_of_batches)\n",
    "    step_numb = 0\n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    cost_values.append(logreg_cost(y, y_pred))\n",
    "    while step_numb < steps:\n",
    "        curr_batch = 0\n",
    "        # shuffle data after every step\n",
    "        X_train, y_train = shuffle(X, y)\n",
    "        while curr_batch < number_of_batches:\n",
    "            # select mini batch from dataset\n",
    "            start_range = batch_size*curr_batch\n",
    "            end_range = batch_size*(curr_batch + 1)\n",
    "            mini_X = X_train[start_range: end_range]\n",
    "            mini_y = y_train[start_range: end_range]\n",
    "            \n",
    "            mini_y_pred = sigmoid(np.dot(mini_X, params))\n",
    "            \n",
    "            # calculate gradient with current mini batch\n",
    "            grad = gradient(mini_X, mini_y_pred, mini_y)\n",
    "            \n",
    "            # update params\n",
    "            params -= step_size * grad\n",
    "            curr_batch += 1\n",
    "            \n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        cost_value = logreg_cost(y, y_pred)\n",
    "        cost_values.append(cost_value)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9561    0.9905    0.9730      1584\n",
      "        male     0.9902    0.9545    0.9720      1584\n",
      "\n",
      "    accuracy                         0.9725      3168\n",
      "   macro avg     0.9732    0.9725    0.9725      3168\n",
      "weighted avg     0.9732    0.9725    0.9725      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.11332612727060082\n",
      "Time for fitting:  5.685015678405762\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_mbgd = LogisticRegression(mini_batch_gradient_descent, 10, 2000)\n",
    "conclusion(logreg_with_mbgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Áp dụng backtracking (1 ví dụ cho thuật toán Gradient Descent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_with_backtracking(X, y, step_size_init, steps, gradient, logreg_cost, cost_values, alpha=0.5, beta=0.5):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    step_numb = 0\n",
    "    prev_cost = None\n",
    "    cost = logreg_cost(y, y_pred)\n",
    "    cost_values.append(cost)\n",
    "    max_step_inside = 20\n",
    "    while step_numb < steps:\n",
    "        step_size = step_size_init\n",
    "        prev_cost = cost\n",
    "        grad = gradient(X, y_pred, y)\n",
    "        params -= step_size * grad\n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        cost = logreg_cost(y, y_pred)\n",
    "        grad_norm = np.linalg.norm(grad)\n",
    "        step_inside = 0\n",
    "        while step_inside < max_step_inside and cost > prev_cost - alpha * step_size * grad_norm**2:\n",
    "            step_size *= beta\n",
    "            step_inside += 1\n",
    "        cost_values.append(cost)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9771    0.9716    0.9744      1584\n",
      "        male     0.9718    0.9773    0.9745      1584\n",
      "\n",
      "    accuracy                         0.9744      3168\n",
      "   macro avg     0.9744    0.9744    0.9744      3168\n",
      "weighted avg     0.9744    0.9744    0.9744      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.08822844753809087\n",
      "Time for fitting:  0.8836171627044678\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_gd_bt = LogisticRegression(gradient_descent_with_backtracking, 10, 2000)\n",
    "conclusion(logreg_with_gd_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:common]",
   "language": "python",
   "name": "conda-env-common-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
