{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load dữ liệu voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice=pd.read_csv('voice.csv')\n",
    "voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "39e154cb54356acfac8c2edd1e565b42edf0b502",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.057126</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>0.140456</td>\n",
       "      <td>0.224765</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>3.140168</td>\n",
       "      <td>36.568461</td>\n",
       "      <td>0.895127</td>\n",
       "      <td>0.408216</td>\n",
       "      <td>0.165282</td>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.142807</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.258842</td>\n",
       "      <td>0.829211</td>\n",
       "      <td>0.052647</td>\n",
       "      <td>5.047277</td>\n",
       "      <td>4.994630</td>\n",
       "      <td>0.173752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.036360</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.042783</td>\n",
       "      <td>4.240529</td>\n",
       "      <td>134.928661</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.177521</td>\n",
       "      <td>0.077203</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>0.525205</td>\n",
       "      <td>0.063299</td>\n",
       "      <td>3.521157</td>\n",
       "      <td>3.520039</td>\n",
       "      <td>0.119454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.018363</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.042946</td>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.141735</td>\n",
       "      <td>2.068455</td>\n",
       "      <td>0.738651</td>\n",
       "      <td>0.036876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.055565</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.041954</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.111087</td>\n",
       "      <td>0.208747</td>\n",
       "      <td>0.042560</td>\n",
       "      <td>1.649569</td>\n",
       "      <td>5.669547</td>\n",
       "      <td>0.861811</td>\n",
       "      <td>0.258041</td>\n",
       "      <td>0.118016</td>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.116998</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.419828</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.070312</td>\n",
       "      <td>2.044922</td>\n",
       "      <td>0.099766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.059155</td>\n",
       "      <td>0.190032</td>\n",
       "      <td>0.140286</td>\n",
       "      <td>0.225684</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>2.197101</td>\n",
       "      <td>8.318463</td>\n",
       "      <td>0.901767</td>\n",
       "      <td>0.396335</td>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.140519</td>\n",
       "      <td>0.046110</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.765795</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>4.992188</td>\n",
       "      <td>4.945312</td>\n",
       "      <td>0.139357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.067020</td>\n",
       "      <td>0.210618</td>\n",
       "      <td>0.175939</td>\n",
       "      <td>0.243660</td>\n",
       "      <td>0.114175</td>\n",
       "      <td>2.931694</td>\n",
       "      <td>13.648905</td>\n",
       "      <td>0.928713</td>\n",
       "      <td>0.533676</td>\n",
       "      <td>0.221104</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.169581</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>0.277457</td>\n",
       "      <td>1.177166</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>7.007812</td>\n",
       "      <td>6.992188</td>\n",
       "      <td>0.209183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.115273</td>\n",
       "      <td>0.261224</td>\n",
       "      <td>0.247347</td>\n",
       "      <td>0.273469</td>\n",
       "      <td>0.252225</td>\n",
       "      <td>34.725453</td>\n",
       "      <td>1309.612887</td>\n",
       "      <td>0.981997</td>\n",
       "      <td>0.842936</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.237636</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.279114</td>\n",
       "      <td>2.957682</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>21.867188</td>\n",
       "      <td>21.843750</td>\n",
       "      <td>0.932374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanfreq           sd       median          Q25          Q75  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.180907     0.057126     0.185621     0.140456     0.224765   \n",
       "std       0.029918     0.016652     0.036360     0.048680     0.023639   \n",
       "min       0.039363     0.018363     0.010975     0.000229     0.042946   \n",
       "25%       0.163662     0.041954     0.169593     0.111087     0.208747   \n",
       "50%       0.184838     0.059155     0.190032     0.140286     0.225684   \n",
       "75%       0.199146     0.067020     0.210618     0.175939     0.243660   \n",
       "max       0.251124     0.115273     0.261224     0.247347     0.273469   \n",
       "\n",
       "               IQR         skew         kurt       sp.ent          sfm  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.084309     3.140168    36.568461     0.895127     0.408216   \n",
       "std       0.042783     4.240529   134.928661     0.044980     0.177521   \n",
       "min       0.014558     0.141735     2.068455     0.738651     0.036876   \n",
       "25%       0.042560     1.649569     5.669547     0.861811     0.258041   \n",
       "50%       0.094280     2.197101     8.318463     0.901767     0.396335   \n",
       "75%       0.114175     2.931694    13.648905     0.928713     0.533676   \n",
       "max       0.252225    34.725453  1309.612887     0.981997     0.842936   \n",
       "\n",
       "              mode     centroid      meanfun       minfun       maxfun  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.165282     0.180907     0.142807     0.036802     0.258842   \n",
       "std       0.077203     0.029918     0.032304     0.019220     0.030077   \n",
       "min       0.000000     0.039363     0.055565     0.009775     0.103093   \n",
       "25%       0.118016     0.163662     0.116998     0.018223     0.253968   \n",
       "50%       0.186599     0.184838     0.140519     0.046110     0.271186   \n",
       "75%       0.221104     0.199146     0.169581     0.047904     0.277457   \n",
       "max       0.280000     0.251124     0.237636     0.204082     0.279114   \n",
       "\n",
       "           meandom       mindom       maxdom      dfrange      modindx  \n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  \n",
       "mean      0.829211     0.052647     5.047277     4.994630     0.173752  \n",
       "std       0.525205     0.063299     3.521157     3.520039     0.119454  \n",
       "min       0.007812     0.004883     0.007812     0.000000     0.000000  \n",
       "25%       0.419828     0.007812     2.070312     2.044922     0.099766  \n",
       "50%       0.765795     0.023438     4.992188     4.945312     0.139357  \n",
       "75%       1.177166     0.070312     7.007812     6.992188     0.209183  \n",
       "max       2.957682     0.458984    21.867188    21.843750     0.932374  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5966f35aea13387065d525aabdcceaa809e08eeb"
   },
   "source": [
    "## II. Chuẩn hóa dữ liệu đầu vào và sử dụng biến giả cho nhãn labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "523e9d19559457ef6269c8ff9f68a1fd15a6a3fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "voice[\"label\"] = le.fit_transform(voice[\"label\"])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "dacdfb24e542b09bfacbf9dd9dfe497b630c02d1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.473409</td>\n",
       "      <td>0.084125</td>\n",
       "      <td>0.060063</td>\n",
       "      <td>0.204956</td>\n",
       "      <td>0.254828</td>\n",
       "      <td>0.367853</td>\n",
       "      <td>0.208279</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.564526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.157706</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.981526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.505075</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.077635</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.246961</td>\n",
       "      <td>0.644279</td>\n",
       "      <td>0.483766</td>\n",
       "      <td>0.630964</td>\n",
       "      <td>0.591578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.287642</td>\n",
       "      <td>0.031140</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.056449</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179222</td>\n",
       "      <td>0.675536</td>\n",
       "      <td>0.102873</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.385912</td>\n",
       "      <td>0.457148</td>\n",
       "      <td>0.885255</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.442738</td>\n",
       "      <td>0.548382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179222</td>\n",
       "      <td>0.236945</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>0.954963</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.049885</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.554611</td>\n",
       "      <td>0.587559</td>\n",
       "      <td>0.389906</td>\n",
       "      <td>0.715802</td>\n",
       "      <td>0.407358</td>\n",
       "      <td>0.031549</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.923261</td>\n",
       "      <td>0.856457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.183442</td>\n",
       "      <td>0.041287</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.065659</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.265043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452195</td>\n",
       "      <td>0.627209</td>\n",
       "      <td>0.454272</td>\n",
       "      <td>0.317627</td>\n",
       "      <td>0.707515</td>\n",
       "      <td>0.474474</td>\n",
       "      <td>0.027742</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.958736</td>\n",
       "      <td>0.926348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452195</td>\n",
       "      <td>0.279190</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.929285</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.250536</td>\n",
       "      <td>0.250715</td>\n",
       "      <td>0.223380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "0  0.096419  0.473409  0.084125  0.060063  0.204956  0.254828  0.367853   \n",
       "1  0.125828  0.505075  0.116900  0.077635  0.215683  0.246961  0.644279   \n",
       "2  0.179222  0.675536  0.102873  0.034284  0.385912  0.457148  0.885255   \n",
       "3  0.528261  0.554611  0.587559  0.389906  0.715802  0.407358  0.031549   \n",
       "4  0.452195  0.627209  0.454272  0.317627  0.707515  0.474474  0.027742   \n",
       "\n",
       "       kurt    sp.ent       sfm  ...  centroid   meanfun    minfun    maxfun  \\\n",
       "0  0.208279  0.635798  0.564526  ...  0.096419  0.157706  0.030501  0.981526   \n",
       "1  0.483766  0.630964  0.591578  ...  0.125828  0.287642  0.031140  0.834600   \n",
       "2  0.782275  0.442738  0.548382  ...  0.179222  0.236945  0.030264  0.954963   \n",
       "3  0.001613  0.923261  0.856457  ...  0.528261  0.183442  0.041287  0.834600   \n",
       "4  0.001732  0.958736  0.926348  ...  0.452195  0.279190  0.036829  0.929285   \n",
       "\n",
       "    meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.000000  0.006452  0.000000  0.000000  0.000000    1.0  \n",
       "1  0.000407  0.006452  0.002144  0.002146  0.056449    1.0  \n",
       "2  0.000060  0.006452  0.000357  0.000358  0.049885    1.0  \n",
       "3  0.065659  0.006452  0.025375  0.025393  0.265043    1.0  \n",
       "4  0.238994  0.006452  0.250536  0.250715  0.223380    1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice[:]=preprocessing.MinMaxScaler().fit_transform(voice)\n",
    "voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.668412</td>\n",
       "      <td>0.399987</td>\n",
       "      <td>0.697887</td>\n",
       "      <td>0.567448</td>\n",
       "      <td>0.788722</td>\n",
       "      <td>0.293484</td>\n",
       "      <td>0.086701</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>0.643020</td>\n",
       "      <td>0.460686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668412</td>\n",
       "      <td>0.479161</td>\n",
       "      <td>0.139093</td>\n",
       "      <td>0.884834</td>\n",
       "      <td>0.278452</td>\n",
       "      <td>0.105184</td>\n",
       "      <td>0.230540</td>\n",
       "      <td>0.228653</td>\n",
       "      <td>0.186354</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.171832</td>\n",
       "      <td>0.145295</td>\n",
       "      <td>0.196990</td>\n",
       "      <td>0.102546</td>\n",
       "      <td>0.180012</td>\n",
       "      <td>0.122616</td>\n",
       "      <td>0.103192</td>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.220233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.177428</td>\n",
       "      <td>0.098916</td>\n",
       "      <td>0.170873</td>\n",
       "      <td>0.178043</td>\n",
       "      <td>0.139395</td>\n",
       "      <td>0.161082</td>\n",
       "      <td>0.161146</td>\n",
       "      <td>0.128119</td>\n",
       "      <td>0.500079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.586978</td>\n",
       "      <td>0.243425</td>\n",
       "      <td>0.633838</td>\n",
       "      <td>0.448602</td>\n",
       "      <td>0.719235</td>\n",
       "      <td>0.117820</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.506112</td>\n",
       "      <td>0.274377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586978</td>\n",
       "      <td>0.337413</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.857144</td>\n",
       "      <td>0.139672</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.094353</td>\n",
       "      <td>0.093616</td>\n",
       "      <td>0.107002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.686980</td>\n",
       "      <td>0.420925</td>\n",
       "      <td>0.715516</td>\n",
       "      <td>0.566764</td>\n",
       "      <td>0.792710</td>\n",
       "      <td>0.335436</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.670306</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686980</td>\n",
       "      <td>0.466594</td>\n",
       "      <td>0.186995</td>\n",
       "      <td>0.954963</td>\n",
       "      <td>0.256955</td>\n",
       "      <td>0.040860</td>\n",
       "      <td>0.228020</td>\n",
       "      <td>0.226395</td>\n",
       "      <td>0.149465</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.502086</td>\n",
       "      <td>0.797777</td>\n",
       "      <td>0.711036</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.419146</td>\n",
       "      <td>0.080673</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.781040</td>\n",
       "      <td>0.616331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.626213</td>\n",
       "      <td>0.196231</td>\n",
       "      <td>0.990585</td>\n",
       "      <td>0.396408</td>\n",
       "      <td>0.144086</td>\n",
       "      <td>0.320229</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>0.224355</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanfreq           sd       median          Q25          Q75  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.668412     0.399987     0.697887     0.567448     0.788722   \n",
       "std       0.141282     0.171832     0.145295     0.196990     0.102546   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.586978     0.243425     0.633838     0.448602     0.719235   \n",
       "50%       0.686980     0.420925     0.715516     0.566764     0.792710   \n",
       "75%       0.754545     0.502086     0.797777     0.711036     0.870690   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               IQR         skew         kurt       sp.ent          sfm  ...  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  ...   \n",
       "mean      0.293484     0.086701     0.026385     0.643020     0.460686  ...   \n",
       "std       0.180012     0.122616     0.103192     0.184838     0.220233  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.117820     0.043600     0.002754     0.506112     0.274377  ...   \n",
       "50%       0.335436     0.059432     0.004780     0.670306     0.445946  ...   \n",
       "75%       0.419146     0.080673     0.008857     0.781040     0.616331  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "          centroid      meanfun       minfun       maxfun      meandom  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.668412     0.479161     0.139093     0.884834     0.278452   \n",
       "std       0.141282     0.177428     0.098916     0.170873     0.178043   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.586978     0.337413     0.043478     0.857144     0.139672   \n",
       "50%       0.686980     0.466594     0.186995     0.954963     0.256955   \n",
       "75%       0.754545     0.626213     0.196231     0.990585     0.396408   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            mindom       maxdom      dfrange      modindx        label  \n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  \n",
       "mean      0.105184     0.230540     0.228653     0.186354     0.500000  \n",
       "std       0.139395     0.161082     0.161146     0.128119     0.500079  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.006452     0.094353     0.093616     0.107002     0.000000  \n",
       "50%       0.040860     0.228020     0.226395     0.149465     0.500000  \n",
       "75%       0.144086     0.320229     0.320100     0.224355     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "01c6142330ed1ac21db52dd832e8d14b4a51ec91"
   },
   "outputs": [],
   "source": [
    "X = voice.iloc[:, :-1]\n",
    "y = voice[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 20)\n",
      "(3168,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Các hàm và thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['female', 'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cost_curve(cost_values):\n",
    "    plt.plot(cost_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conclusion(model, cost=None):\n",
    "    start_time = time.time()\n",
    "    model.fit(X,y)\n",
    "    total_time = time.time() - start_time\n",
    "    y_pred=model.predict(X)\n",
    "    y_predll = (y_pred >= 0.5).astype(int)\n",
    "    if cost is None: cost = model.cost\n",
    "    print(classification_report(y, y_predll, target_names=target_names, digits=4))\n",
    "    print(\"===================\")\n",
    "    print(\"Mean loss: \", cost(y, y_pred))\n",
    "    print(\"Time for fitting: \", total_time)\n",
    "    print(\"===================\")\n",
    "    if hasattr(model, \"cost_values\"):\n",
    "        draw_cost_curve(model.cost_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Sử dụng phương pháp tối ưu Stochastic Average Gradient Descent từ thư viện Scikit-learn cho mô hình Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "19d364d29be43bc856b31f0ddec1d5a50a88e2c5"
   },
   "outputs": [],
   "source": [
    "model = SKLogisticRegression(penalty='none', tol=0.0001, solver='lbfgs', max_iter=500, verbose=0, n_jobs=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9771    0.9716    0.9744      1584\n",
      "        male     0.9718    0.9773    0.9745      1584\n",
      "\n",
      "    accuracy                         0.9744      3168\n",
      "   macro avg     0.9744    0.9744    0.9744      3168\n",
      "weighted avg     0.9744    0.9744    0.9744      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.8831050725606462\n",
      "Time for fitting:  0.06397438049316406\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "conclusion(model, log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Tự xây dựng các thuật toán tối ưu Gradient Descent, Stochastic Gradient Descent và Mini Batch Gradient Descent cho mô hình Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.e**(-z))\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, optimizer, step_size, steps=100):\n",
    "        self.optimizer = optimizer\n",
    "        self.step_size = step_size\n",
    "        self.steps = steps\n",
    "        self.params = None\n",
    "        self.cost_values = list()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "        y = np.expand_dims(y, axis=1)\n",
    "        self.params = self.optimizer(X, y, self.step_size, self.steps, self.gradient, self.cost, self.cost_values)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "        y_pred = sigmoid(np.dot(X, self.params))\n",
    "        return np.squeeze(y_pred, axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def gradient(X, y_pred, y):\n",
    "        return 1/ y.shape[0] * np.dot(X.transpose(), (y_pred - y))\n",
    "\n",
    "    @staticmethod\n",
    "    def cost(y, y_pred):\n",
    "        return -1/y.shape[0] * np.squeeze(np.dot(y.transpose(), np.log(y_pred)) + np.dot((1 - y).transpose(), np.log(1 - y_pred)))[()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    step_numb = 0\n",
    "    while step_numb < steps:\n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        grad = gradient(X, y_pred, y)\n",
    "        params -= step_size * grad\n",
    "        cost_value = logreg_cost(y, y_pred)\n",
    "        cost_values.append(cost_value)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.7597    0.7923    0.7756      1584\n",
      "        male     0.7830    0.7494    0.7658      1584\n",
      "\n",
      "    accuracy                         0.7708      3168\n",
      "   macro avg     0.7713    0.7708    0.7707      3168\n",
      "weighted avg     0.7713    0.7708    0.7707      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.5768001864620869\n",
      "Time for fitting:  0.05095505714416504\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_gd = LogisticRegression(gradient_descent, 10**-1, 100)\n",
    "conclusion(logreg_with_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochactis Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values):\n",
    "    N = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "#     params = np.random.randn(d, 1)\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    step_numb = 0\n",
    "    \n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    cost_values.append(logreg_cost(y, y_pred))\n",
    "    \n",
    "    check_w_after = 1\n",
    "    tol = 0.001\n",
    "    \n",
    "    while step_numb < steps:\n",
    "        # shuffle data after every step\n",
    "        shuffled_idxs = np.random.permutation(N)\n",
    "        for i in shuffled_idxs:\n",
    "            curr_X = np.expand_dims(X[i], axis=0)\n",
    "            curr_y = y[i]\n",
    "            curr_y_pred = sigmoid(np.dot(curr_X, params))\n",
    "            \n",
    "            # calculate gradient with current datapoint\n",
    "            grad = gradient(curr_X, curr_y_pred, curr_y)\n",
    "            \n",
    "            # update params\n",
    "            params -= step_size * grad\n",
    "            \n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        cost_value = logreg_cost(y, y_pred)\n",
    "        \n",
    "        cost_values.append(cost_value)\n",
    "        \n",
    "        # stop using tolerance criteria\n",
    "        if step_numb % check_w_after == 0 and cost_value < tol: \n",
    "            print(\"Total steps: \", step_numb)\n",
    "            break\n",
    "            \n",
    "#         # step size decays\n",
    "#         step_size /= 2    \n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9760    0.9754    0.9757      1584\n",
      "        male     0.9754    0.9760    0.9757      1584\n",
      "\n",
      "    accuracy                         0.9757      3168\n",
      "   macro avg     0.9757    0.9757    0.9757      3168\n",
      "weighted avg     0.9757    0.9757    0.9757      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.08858893621386311\n",
      "Time for fitting:  11.621954679489136\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_sgd = LogisticRegression(stochastic_gradient_descent, 10**-1, 100)\n",
    "conclusion(logreg_with_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values, batch_size=64):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    number_of_batches = y.shape[0] // batch_size + (0 if y.shape[0] % batch_size == 0 else 1)\n",
    "    print(\"Number of batches: \", number_of_batches)\n",
    "    step_numb = 0\n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    cost_values.append(logreg_cost(y, y_pred))\n",
    "    while step_numb < steps:\n",
    "        curr_batch = 0\n",
    "        # shuffle data after every step\n",
    "        X_train, y_train = shuffle(X, y)\n",
    "        while curr_batch < number_of_batches:\n",
    "            # select mini batch from dataset\n",
    "            start_range = batch_size*curr_batch\n",
    "            end_range = batch_size*(curr_batch + 1)\n",
    "            mini_X = X_train[start_range: end_range]\n",
    "            mini_y = y_train[start_range: end_range]\n",
    "            \n",
    "            mini_y_pred = sigmoid(np.dot(mini_X, params))\n",
    "            \n",
    "            # calculate gradient with current mini batch\n",
    "            grad = gradient(mini_X, mini_y_pred, mini_y)\n",
    "            \n",
    "            # update params\n",
    "            params -= step_size * grad\n",
    "            curr_batch += 1\n",
    "            \n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        cost_value = logreg_cost(y, y_pred)\n",
    "        cost_values.append(cost_value)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9767    0.9508    0.9635      1584\n",
      "        male     0.9520    0.9773    0.9645      1584\n",
      "\n",
      "    accuracy                         0.9640      3168\n",
      "   macro avg     0.9643    0.9640    0.9640      3168\n",
      "weighted avg     0.9643    0.9640    0.9640      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.16850080478597237\n",
      "Time for fitting:  0.18444323539733887\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_mbgd = LogisticRegression(mini_batch_gradient_descent, 10**-1, 100)\n",
    "conclusion(logreg_with_mbgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Áp dụng backtracking (1 ví dụ cho thuật toán Gradient Descent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_with_backtracking(X, y, step_size, steps, gradient, logreg_cost, cost_values, alpha=0.5, beta=0.5):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    step_numb = 0\n",
    "    prev_cost = None\n",
    "    cost = logreg_cost(y, y_pred)\n",
    "    cost_values.append(cost)\n",
    "    while step_numb < steps:\n",
    "        prev_cost = cost\n",
    "        grad = gradient(X, y_pred, y)\n",
    "        params -= step_size * grad\n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        cost = logreg_cost(y, y_pred)\n",
    "        grad_norm = np.linalg.norm(grad)\n",
    "        margin = alpha * step_size * grad_norm**2\n",
    "        \n",
    "        # Backtracking to shrink step_size\n",
    "        while cost > prev_cost - margin:\n",
    "            step_size *= beta\n",
    "            params -= step_size * grad\n",
    "            y_pred = sigmoid(np.dot(X, params))\n",
    "            cost = logreg_cost(y, y_pred)\n",
    "            margin = alpha * step_size * grad_norm**2\n",
    "            \n",
    "        cost_values.append(cost)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.7597    0.7923    0.7756      1584\n",
      "        male     0.7830    0.7494    0.7658      1584\n",
      "\n",
      "    accuracy                         0.7708      3168\n",
      "   macro avg     0.7713    0.7708    0.7707      3168\n",
      "weighted avg     0.7713    0.7708    0.7707      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.5768001864620869\n",
      "Time for fitting:  0.05860471725463867\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_gd_bt = LogisticRegression(gradient_descent_with_backtracking, 10**-1, 100)\n",
    "conclusion(logreg_with_gd_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:common]",
   "language": "python",
   "name": "conda-env-common-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
