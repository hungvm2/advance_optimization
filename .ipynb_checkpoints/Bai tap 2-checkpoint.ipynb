{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load dữ liệu voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice=pd.read_csv('voice.csv')\n",
    "voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "39e154cb54356acfac8c2edd1e565b42edf0b502",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.057126</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>0.140456</td>\n",
       "      <td>0.224765</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>3.140168</td>\n",
       "      <td>36.568461</td>\n",
       "      <td>0.895127</td>\n",
       "      <td>0.408216</td>\n",
       "      <td>0.165282</td>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.142807</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.258842</td>\n",
       "      <td>0.829211</td>\n",
       "      <td>0.052647</td>\n",
       "      <td>5.047277</td>\n",
       "      <td>4.994630</td>\n",
       "      <td>0.173752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.036360</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.042783</td>\n",
       "      <td>4.240529</td>\n",
       "      <td>134.928661</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.177521</td>\n",
       "      <td>0.077203</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>0.525205</td>\n",
       "      <td>0.063299</td>\n",
       "      <td>3.521157</td>\n",
       "      <td>3.520039</td>\n",
       "      <td>0.119454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.018363</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.042946</td>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.141735</td>\n",
       "      <td>2.068455</td>\n",
       "      <td>0.738651</td>\n",
       "      <td>0.036876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.055565</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.041954</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.111087</td>\n",
       "      <td>0.208747</td>\n",
       "      <td>0.042560</td>\n",
       "      <td>1.649569</td>\n",
       "      <td>5.669547</td>\n",
       "      <td>0.861811</td>\n",
       "      <td>0.258041</td>\n",
       "      <td>0.118016</td>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.116998</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.419828</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.070312</td>\n",
       "      <td>2.044922</td>\n",
       "      <td>0.099766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.059155</td>\n",
       "      <td>0.190032</td>\n",
       "      <td>0.140286</td>\n",
       "      <td>0.225684</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>2.197101</td>\n",
       "      <td>8.318463</td>\n",
       "      <td>0.901767</td>\n",
       "      <td>0.396335</td>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.140519</td>\n",
       "      <td>0.046110</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.765795</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>4.992188</td>\n",
       "      <td>4.945312</td>\n",
       "      <td>0.139357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.067020</td>\n",
       "      <td>0.210618</td>\n",
       "      <td>0.175939</td>\n",
       "      <td>0.243660</td>\n",
       "      <td>0.114175</td>\n",
       "      <td>2.931694</td>\n",
       "      <td>13.648905</td>\n",
       "      <td>0.928713</td>\n",
       "      <td>0.533676</td>\n",
       "      <td>0.221104</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.169581</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>0.277457</td>\n",
       "      <td>1.177166</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>7.007812</td>\n",
       "      <td>6.992188</td>\n",
       "      <td>0.209183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.115273</td>\n",
       "      <td>0.261224</td>\n",
       "      <td>0.247347</td>\n",
       "      <td>0.273469</td>\n",
       "      <td>0.252225</td>\n",
       "      <td>34.725453</td>\n",
       "      <td>1309.612887</td>\n",
       "      <td>0.981997</td>\n",
       "      <td>0.842936</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.237636</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.279114</td>\n",
       "      <td>2.957682</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>21.867188</td>\n",
       "      <td>21.843750</td>\n",
       "      <td>0.932374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanfreq           sd       median          Q25          Q75  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.180907     0.057126     0.185621     0.140456     0.224765   \n",
       "std       0.029918     0.016652     0.036360     0.048680     0.023639   \n",
       "min       0.039363     0.018363     0.010975     0.000229     0.042946   \n",
       "25%       0.163662     0.041954     0.169593     0.111087     0.208747   \n",
       "50%       0.184838     0.059155     0.190032     0.140286     0.225684   \n",
       "75%       0.199146     0.067020     0.210618     0.175939     0.243660   \n",
       "max       0.251124     0.115273     0.261224     0.247347     0.273469   \n",
       "\n",
       "               IQR         skew         kurt       sp.ent          sfm  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.084309     3.140168    36.568461     0.895127     0.408216   \n",
       "std       0.042783     4.240529   134.928661     0.044980     0.177521   \n",
       "min       0.014558     0.141735     2.068455     0.738651     0.036876   \n",
       "25%       0.042560     1.649569     5.669547     0.861811     0.258041   \n",
       "50%       0.094280     2.197101     8.318463     0.901767     0.396335   \n",
       "75%       0.114175     2.931694    13.648905     0.928713     0.533676   \n",
       "max       0.252225    34.725453  1309.612887     0.981997     0.842936   \n",
       "\n",
       "              mode     centroid      meanfun       minfun       maxfun  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.165282     0.180907     0.142807     0.036802     0.258842   \n",
       "std       0.077203     0.029918     0.032304     0.019220     0.030077   \n",
       "min       0.000000     0.039363     0.055565     0.009775     0.103093   \n",
       "25%       0.118016     0.163662     0.116998     0.018223     0.253968   \n",
       "50%       0.186599     0.184838     0.140519     0.046110     0.271186   \n",
       "75%       0.221104     0.199146     0.169581     0.047904     0.277457   \n",
       "max       0.280000     0.251124     0.237636     0.204082     0.279114   \n",
       "\n",
       "           meandom       mindom       maxdom      dfrange      modindx  \n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  \n",
       "mean      0.829211     0.052647     5.047277     4.994630     0.173752  \n",
       "std       0.525205     0.063299     3.521157     3.520039     0.119454  \n",
       "min       0.007812     0.004883     0.007812     0.000000     0.000000  \n",
       "25%       0.419828     0.007812     2.070312     2.044922     0.099766  \n",
       "50%       0.765795     0.023438     4.992188     4.945312     0.139357  \n",
       "75%       1.177166     0.070312     7.007812     6.992188     0.209183  \n",
       "max       2.957682     0.458984    21.867188    21.843750     0.932374  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5966f35aea13387065d525aabdcceaa809e08eeb"
   },
   "source": [
    "## II. Chuẩn hóa dữ liệu đầu vào và sử dụng biến giả cho nhãn labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "523e9d19559457ef6269c8ff9f68a1fd15a6a3fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "voice[\"label\"] = le.fit_transform(voice[\"label\"])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "dacdfb24e542b09bfacbf9dd9dfe497b630c02d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.473409</td>\n",
       "      <td>0.084125</td>\n",
       "      <td>0.060063</td>\n",
       "      <td>0.204956</td>\n",
       "      <td>0.254828</td>\n",
       "      <td>0.367853</td>\n",
       "      <td>0.208279</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.564526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.157706</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.981526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.505075</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.077635</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.246961</td>\n",
       "      <td>0.644279</td>\n",
       "      <td>0.483766</td>\n",
       "      <td>0.630964</td>\n",
       "      <td>0.591578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.287642</td>\n",
       "      <td>0.031140</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.056449</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179222</td>\n",
       "      <td>0.675536</td>\n",
       "      <td>0.102873</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.385912</td>\n",
       "      <td>0.457148</td>\n",
       "      <td>0.885255</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.442738</td>\n",
       "      <td>0.548382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179222</td>\n",
       "      <td>0.236945</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>0.954963</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.049885</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.554611</td>\n",
       "      <td>0.587559</td>\n",
       "      <td>0.389906</td>\n",
       "      <td>0.715802</td>\n",
       "      <td>0.407358</td>\n",
       "      <td>0.031549</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.923261</td>\n",
       "      <td>0.856457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.183442</td>\n",
       "      <td>0.041287</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.065659</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.265043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452195</td>\n",
       "      <td>0.627209</td>\n",
       "      <td>0.454272</td>\n",
       "      <td>0.317627</td>\n",
       "      <td>0.707515</td>\n",
       "      <td>0.474474</td>\n",
       "      <td>0.027742</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.958736</td>\n",
       "      <td>0.926348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452195</td>\n",
       "      <td>0.279190</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.929285</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.250536</td>\n",
       "      <td>0.250715</td>\n",
       "      <td>0.223380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "0  0.096419  0.473409  0.084125  0.060063  0.204956  0.254828  0.367853   \n",
       "1  0.125828  0.505075  0.116900  0.077635  0.215683  0.246961  0.644279   \n",
       "2  0.179222  0.675536  0.102873  0.034284  0.385912  0.457148  0.885255   \n",
       "3  0.528261  0.554611  0.587559  0.389906  0.715802  0.407358  0.031549   \n",
       "4  0.452195  0.627209  0.454272  0.317627  0.707515  0.474474  0.027742   \n",
       "\n",
       "       kurt    sp.ent       sfm  ...  centroid   meanfun    minfun    maxfun  \\\n",
       "0  0.208279  0.635798  0.564526  ...  0.096419  0.157706  0.030501  0.981526   \n",
       "1  0.483766  0.630964  0.591578  ...  0.125828  0.287642  0.031140  0.834600   \n",
       "2  0.782275  0.442738  0.548382  ...  0.179222  0.236945  0.030264  0.954963   \n",
       "3  0.001613  0.923261  0.856457  ...  0.528261  0.183442  0.041287  0.834600   \n",
       "4  0.001732  0.958736  0.926348  ...  0.452195  0.279190  0.036829  0.929285   \n",
       "\n",
       "    meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.000000  0.006452  0.000000  0.000000  0.000000    1.0  \n",
       "1  0.000407  0.006452  0.002144  0.002146  0.056449    1.0  \n",
       "2  0.000060  0.006452  0.000357  0.000358  0.049885    1.0  \n",
       "3  0.065659  0.006452  0.025375  0.025393  0.265043    1.0  \n",
       "4  0.238994  0.006452  0.250536  0.250715  0.223380    1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice[:]=preprocessing.MinMaxScaler().fit_transform(voice)\n",
    "voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "01c6142330ed1ac21db52dd832e8d14b4a51ec91"
   },
   "outputs": [],
   "source": [
    "X = voice.iloc[:, :-1]\n",
    "y = voice[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 20)\n",
      "(3168,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Các hàm và thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['female', 'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cost_curve(cost_values):\n",
    "    plt.plot(cost_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conclusion(model, cost=None):\n",
    "    start_time = time.time()\n",
    "    model.fit(X,y)\n",
    "    total_time = time.time() - start_time\n",
    "    y_pred=model.predict(X)\n",
    "    y_predll = (y_pred >= 0.5).astype(int)\n",
    "    if cost is None: cost = model.cost\n",
    "    print(classification_report(y, y_predll, target_names=target_names, digits=4))\n",
    "    print(\"===================\")\n",
    "    print(\"Total loss: \", cost(y, y_pred))\n",
    "    print(\"Time for fitting: \", total_time)\n",
    "    print(\"===================\")\n",
    "    if hasattr(model, \"cost_values\"):\n",
    "        draw_cost_curve(model.cost_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Sử dụng phương pháp tối ưu Stochastic Average Gradient Descent từ thư viện Scikit-learn cho mô hình Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "19d364d29be43bc856b31f0ddec1d5a50a88e2c5"
   },
   "outputs": [],
   "source": [
    "model = SKLogisticRegression(penalty='none', tol=0.0001, solver='lbfgs', max_iter=2000, verbose=0, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9771    0.9716    0.9744      1584\n",
      "        male     0.9718    0.9773    0.9745      1584\n",
      "\n",
      "    accuracy                         0.9744      3168\n",
      "   macro avg     0.9744    0.9744    0.9744      3168\n",
      "weighted avg     0.9744    0.9744    0.9744      3168\n",
      "\n",
      "===================\n",
      "Total loss:  0.8831050725606462\n",
      "Time for fitting:  0.1496293544769287\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "conclusion(model, log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Tự xây dựng các thuật toán tối ưu Gradient Descent, Stochastic Gradient Descent và Mini Batch Gradient Descent cho mô hình Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.e**(-z))\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, optimizer, step_size, steps=1000):\n",
    "        self.optimizer = optimizer\n",
    "        self.step_size = step_size\n",
    "        self.steps = steps\n",
    "        self.params = None\n",
    "        self.cost_values = list()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "        y = np.expand_dims(y, axis=1)\n",
    "        self.params = self.optimizer(X, y, self.step_size, self.steps, self.gradient, self.cost, self.cost_values)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "        y_pred = sigmoid(np.dot(X, self.params))\n",
    "        return np.squeeze(y_pred, axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def gradient(X, y_pred, y):\n",
    "        return np.dot(X.transpose(), (y_pred - y))\n",
    "\n",
    "    @staticmethod\n",
    "    def cost(y, y_pred):\n",
    "        return -1/y.shape[0] * np.sum((y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    step_numb = 0\n",
    "    while step_numb < steps:\n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        grad = gradient(X, y_pred, y)\n",
    "        params -= step_size * grad\n",
    "        cost_values.append(logreg_cost(y, y_pred))\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9764    0.9678    0.9721      1584\n",
      "        male     0.9681    0.9766    0.9723      1584\n",
      "\n",
      "    accuracy                         0.9722      3168\n",
      "   macro avg     0.9723    0.9722    0.9722      3168\n",
      "weighted avg     0.9723    0.9722    0.9722      3168\n",
      "\n",
      "===================\n",
      "Total loss:  0.09194347765339539\n",
      "Time for fitting:  0.879605770111084\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_gd = LogisticRegression(gradient_descent, 10**-3, 2000)\n",
    "conclusion(logreg_with_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochactis Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values, batch_size=64):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    number_of_batches = y.shape[0] // batch_size + (0 if y.shape[0] % batch_size == 0 else 1)\n",
    "    print(\"Number of batches: \", number_of_batches)\n",
    "    step_numb = 0\n",
    "    X_train = X.copy()\n",
    "    y_train = y.copy()\n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    cost_values.append(logreg_cost(y, y_pred))\n",
    "    while step_numb < steps:\n",
    "        curr_batch = 0\n",
    "        # shuffle data after every epoch\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        cost_value = 0\n",
    "        while curr_batch < number_of_batches:\n",
    "            # select mini batch from dataset\n",
    "            start_range = batch_size*curr_batch\n",
    "            end_range = batch_size*(curr_batch + 1)\n",
    "            mini_X = X_train[start_range: end_range]\n",
    "            mini_y = y_train[start_range: end_range]\n",
    "            \n",
    "            mini_y_pred = sigmoid(np.dot(mini_X, params))\n",
    "            \n",
    "            # calculate gradient with current mini batch\n",
    "            grad = gradient(mini_X, mini_y_pred, mini_y)\n",
    "            \n",
    "            # update params\n",
    "            params -= step_size * grad\n",
    "            curr_batch += 1\n",
    "            cost_value += logreg_cost(mini_y, mini_y_pred)\n",
    "        cost_values.append(cost_value)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9764    0.9678    0.9721      1584\n",
      "        male     0.9681    0.9766    0.9723      1584\n",
      "\n",
      "    accuracy                         0.9722      3168\n",
      "   macro avg     0.9723    0.9722    0.9722      3168\n",
      "weighted avg     0.9723    0.9722    0.9722      3168\n",
      "\n",
      "===================\n",
      "Total loss:  0.0920072606155532\n",
      "Time for fitting:  2.94049072265625\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_mbgd = LogisticRegression(mini_batch_gradient_descent, 10**-3, 2000)\n",
    "conclusion(logreg_with_mbgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Áp dụng backtracking (1 ví dụ cho thuật toán Gradient Descent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_with_backtracking(X, y, step_size_init, steps, gradient, logreg_cost, cost_values, alpha=0.5, beta=0.5):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    step_numb = 0\n",
    "    prev_cost = None\n",
    "    cost = logreg_cost(y, y_pred)\n",
    "    cost_values.append(cost)\n",
    "    max_step_inside = 20\n",
    "    while step_numb < steps:\n",
    "        step_size = step_size_init\n",
    "        prev_cost = cost\n",
    "        grad = gradient(X, y_pred, y)\n",
    "        params -= step_size * grad\n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        cost = logreg_cost(y, y_pred)\n",
    "        grad_norm = np.linalg.norm(grad)\n",
    "        step_inside = 0\n",
    "        while step_inside < max_step_inside and cost > prev_cost - alpha * step_size * grad_norm**2:\n",
    "            step_size *= beta\n",
    "            step_inside += 1\n",
    "        cost_values.append(cost)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9764    0.9678    0.9721      1584\n",
      "        male     0.9681    0.9766    0.9723      1584\n",
      "\n",
      "    accuracy                         0.9722      3168\n",
      "   macro avg     0.9723    0.9722    0.9722      3168\n",
      "weighted avg     0.9723    0.9722    0.9722      3168\n",
      "\n",
      "===================\n",
      "Total loss:  0.09194347765339539\n",
      "Time for fitting:  1.1186559200286865\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_gd_bt = LogisticRegression(gradient_descent_with_backtracking, 10**-3, 2000)\n",
    "conclusion(logreg_with_gd_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:common]",
   "language": "python",
   "name": "conda-env-common-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
