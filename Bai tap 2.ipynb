{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load dữ liệu voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice=pd.read_csv('voice.csv')\n",
    "voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "39e154cb54356acfac8c2edd1e565b42edf0b502",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.057126</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>0.140456</td>\n",
       "      <td>0.224765</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>3.140168</td>\n",
       "      <td>36.568461</td>\n",
       "      <td>0.895127</td>\n",
       "      <td>0.408216</td>\n",
       "      <td>0.165282</td>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.142807</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.258842</td>\n",
       "      <td>0.829211</td>\n",
       "      <td>0.052647</td>\n",
       "      <td>5.047277</td>\n",
       "      <td>4.994630</td>\n",
       "      <td>0.173752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.036360</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.042783</td>\n",
       "      <td>4.240529</td>\n",
       "      <td>134.928661</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.177521</td>\n",
       "      <td>0.077203</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>0.525205</td>\n",
       "      <td>0.063299</td>\n",
       "      <td>3.521157</td>\n",
       "      <td>3.520039</td>\n",
       "      <td>0.119454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.018363</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.042946</td>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.141735</td>\n",
       "      <td>2.068455</td>\n",
       "      <td>0.738651</td>\n",
       "      <td>0.036876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.055565</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.041954</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.111087</td>\n",
       "      <td>0.208747</td>\n",
       "      <td>0.042560</td>\n",
       "      <td>1.649569</td>\n",
       "      <td>5.669547</td>\n",
       "      <td>0.861811</td>\n",
       "      <td>0.258041</td>\n",
       "      <td>0.118016</td>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.116998</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.419828</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.070312</td>\n",
       "      <td>2.044922</td>\n",
       "      <td>0.099766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.059155</td>\n",
       "      <td>0.190032</td>\n",
       "      <td>0.140286</td>\n",
       "      <td>0.225684</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>2.197101</td>\n",
       "      <td>8.318463</td>\n",
       "      <td>0.901767</td>\n",
       "      <td>0.396335</td>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.140519</td>\n",
       "      <td>0.046110</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.765795</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>4.992188</td>\n",
       "      <td>4.945312</td>\n",
       "      <td>0.139357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.067020</td>\n",
       "      <td>0.210618</td>\n",
       "      <td>0.175939</td>\n",
       "      <td>0.243660</td>\n",
       "      <td>0.114175</td>\n",
       "      <td>2.931694</td>\n",
       "      <td>13.648905</td>\n",
       "      <td>0.928713</td>\n",
       "      <td>0.533676</td>\n",
       "      <td>0.221104</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.169581</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>0.277457</td>\n",
       "      <td>1.177166</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>7.007812</td>\n",
       "      <td>6.992188</td>\n",
       "      <td>0.209183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.115273</td>\n",
       "      <td>0.261224</td>\n",
       "      <td>0.247347</td>\n",
       "      <td>0.273469</td>\n",
       "      <td>0.252225</td>\n",
       "      <td>34.725453</td>\n",
       "      <td>1309.612887</td>\n",
       "      <td>0.981997</td>\n",
       "      <td>0.842936</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.237636</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.279114</td>\n",
       "      <td>2.957682</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>21.867188</td>\n",
       "      <td>21.843750</td>\n",
       "      <td>0.932374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanfreq           sd       median          Q25          Q75  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.180907     0.057126     0.185621     0.140456     0.224765   \n",
       "std       0.029918     0.016652     0.036360     0.048680     0.023639   \n",
       "min       0.039363     0.018363     0.010975     0.000229     0.042946   \n",
       "25%       0.163662     0.041954     0.169593     0.111087     0.208747   \n",
       "50%       0.184838     0.059155     0.190032     0.140286     0.225684   \n",
       "75%       0.199146     0.067020     0.210618     0.175939     0.243660   \n",
       "max       0.251124     0.115273     0.261224     0.247347     0.273469   \n",
       "\n",
       "               IQR         skew         kurt       sp.ent          sfm  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.084309     3.140168    36.568461     0.895127     0.408216   \n",
       "std       0.042783     4.240529   134.928661     0.044980     0.177521   \n",
       "min       0.014558     0.141735     2.068455     0.738651     0.036876   \n",
       "25%       0.042560     1.649569     5.669547     0.861811     0.258041   \n",
       "50%       0.094280     2.197101     8.318463     0.901767     0.396335   \n",
       "75%       0.114175     2.931694    13.648905     0.928713     0.533676   \n",
       "max       0.252225    34.725453  1309.612887     0.981997     0.842936   \n",
       "\n",
       "              mode     centroid      meanfun       minfun       maxfun  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.165282     0.180907     0.142807     0.036802     0.258842   \n",
       "std       0.077203     0.029918     0.032304     0.019220     0.030077   \n",
       "min       0.000000     0.039363     0.055565     0.009775     0.103093   \n",
       "25%       0.118016     0.163662     0.116998     0.018223     0.253968   \n",
       "50%       0.186599     0.184838     0.140519     0.046110     0.271186   \n",
       "75%       0.221104     0.199146     0.169581     0.047904     0.277457   \n",
       "max       0.280000     0.251124     0.237636     0.204082     0.279114   \n",
       "\n",
       "           meandom       mindom       maxdom      dfrange      modindx  \n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  \n",
       "mean      0.829211     0.052647     5.047277     4.994630     0.173752  \n",
       "std       0.525205     0.063299     3.521157     3.520039     0.119454  \n",
       "min       0.007812     0.004883     0.007812     0.000000     0.000000  \n",
       "25%       0.419828     0.007812     2.070312     2.044922     0.099766  \n",
       "50%       0.765795     0.023438     4.992188     4.945312     0.139357  \n",
       "75%       1.177166     0.070312     7.007812     6.992188     0.209183  \n",
       "max       2.957682     0.458984    21.867188    21.843750     0.932374  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5966f35aea13387065d525aabdcceaa809e08eeb"
   },
   "source": [
    "## II. Chuẩn hóa dữ liệu đầu vào và sử dụng biến giả cho nhãn labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "523e9d19559457ef6269c8ff9f68a1fd15a6a3fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "voice[\"label\"] = le.fit_transform(voice[\"label\"])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "dacdfb24e542b09bfacbf9dd9dfe497b630c02d1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.473409</td>\n",
       "      <td>0.084125</td>\n",
       "      <td>0.060063</td>\n",
       "      <td>0.204956</td>\n",
       "      <td>0.254828</td>\n",
       "      <td>0.367853</td>\n",
       "      <td>0.208279</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.564526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.157706</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.981526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.505075</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.077635</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.246961</td>\n",
       "      <td>0.644279</td>\n",
       "      <td>0.483766</td>\n",
       "      <td>0.630964</td>\n",
       "      <td>0.591578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.287642</td>\n",
       "      <td>0.031140</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.056449</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179222</td>\n",
       "      <td>0.675536</td>\n",
       "      <td>0.102873</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.385912</td>\n",
       "      <td>0.457148</td>\n",
       "      <td>0.885255</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.442738</td>\n",
       "      <td>0.548382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179222</td>\n",
       "      <td>0.236945</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>0.954963</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.049885</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.554611</td>\n",
       "      <td>0.587559</td>\n",
       "      <td>0.389906</td>\n",
       "      <td>0.715802</td>\n",
       "      <td>0.407358</td>\n",
       "      <td>0.031549</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.923261</td>\n",
       "      <td>0.856457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.183442</td>\n",
       "      <td>0.041287</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.065659</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.265043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452195</td>\n",
       "      <td>0.627209</td>\n",
       "      <td>0.454272</td>\n",
       "      <td>0.317627</td>\n",
       "      <td>0.707515</td>\n",
       "      <td>0.474474</td>\n",
       "      <td>0.027742</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.958736</td>\n",
       "      <td>0.926348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452195</td>\n",
       "      <td>0.279190</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.929285</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.250536</td>\n",
       "      <td>0.250715</td>\n",
       "      <td>0.223380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "0  0.096419  0.473409  0.084125  0.060063  0.204956  0.254828  0.367853   \n",
       "1  0.125828  0.505075  0.116900  0.077635  0.215683  0.246961  0.644279   \n",
       "2  0.179222  0.675536  0.102873  0.034284  0.385912  0.457148  0.885255   \n",
       "3  0.528261  0.554611  0.587559  0.389906  0.715802  0.407358  0.031549   \n",
       "4  0.452195  0.627209  0.454272  0.317627  0.707515  0.474474  0.027742   \n",
       "\n",
       "       kurt    sp.ent       sfm  ...  centroid   meanfun    minfun    maxfun  \\\n",
       "0  0.208279  0.635798  0.564526  ...  0.096419  0.157706  0.030501  0.981526   \n",
       "1  0.483766  0.630964  0.591578  ...  0.125828  0.287642  0.031140  0.834600   \n",
       "2  0.782275  0.442738  0.548382  ...  0.179222  0.236945  0.030264  0.954963   \n",
       "3  0.001613  0.923261  0.856457  ...  0.528261  0.183442  0.041287  0.834600   \n",
       "4  0.001732  0.958736  0.926348  ...  0.452195  0.279190  0.036829  0.929285   \n",
       "\n",
       "    meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.000000  0.006452  0.000000  0.000000  0.000000    1.0  \n",
       "1  0.000407  0.006452  0.002144  0.002146  0.056449    1.0  \n",
       "2  0.000060  0.006452  0.000357  0.000358  0.049885    1.0  \n",
       "3  0.065659  0.006452  0.025375  0.025393  0.265043    1.0  \n",
       "4  0.238994  0.006452  0.250536  0.250715  0.223380    1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice[:]=preprocessing.MinMaxScaler().fit_transform(voice)\n",
    "voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.668412</td>\n",
       "      <td>0.399987</td>\n",
       "      <td>0.697887</td>\n",
       "      <td>0.567448</td>\n",
       "      <td>0.788722</td>\n",
       "      <td>0.293484</td>\n",
       "      <td>0.086701</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>0.643020</td>\n",
       "      <td>0.460686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668412</td>\n",
       "      <td>0.479161</td>\n",
       "      <td>0.139093</td>\n",
       "      <td>0.884834</td>\n",
       "      <td>0.278452</td>\n",
       "      <td>0.105184</td>\n",
       "      <td>0.230540</td>\n",
       "      <td>0.228653</td>\n",
       "      <td>0.186354</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.171832</td>\n",
       "      <td>0.145295</td>\n",
       "      <td>0.196990</td>\n",
       "      <td>0.102546</td>\n",
       "      <td>0.180012</td>\n",
       "      <td>0.122616</td>\n",
       "      <td>0.103192</td>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.220233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.177428</td>\n",
       "      <td>0.098916</td>\n",
       "      <td>0.170873</td>\n",
       "      <td>0.178043</td>\n",
       "      <td>0.139395</td>\n",
       "      <td>0.161082</td>\n",
       "      <td>0.161146</td>\n",
       "      <td>0.128119</td>\n",
       "      <td>0.500079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.586978</td>\n",
       "      <td>0.243425</td>\n",
       "      <td>0.633838</td>\n",
       "      <td>0.448602</td>\n",
       "      <td>0.719235</td>\n",
       "      <td>0.117820</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.506112</td>\n",
       "      <td>0.274377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586978</td>\n",
       "      <td>0.337413</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.857144</td>\n",
       "      <td>0.139672</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.094353</td>\n",
       "      <td>0.093616</td>\n",
       "      <td>0.107002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.686980</td>\n",
       "      <td>0.420925</td>\n",
       "      <td>0.715516</td>\n",
       "      <td>0.566764</td>\n",
       "      <td>0.792710</td>\n",
       "      <td>0.335436</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.670306</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686980</td>\n",
       "      <td>0.466594</td>\n",
       "      <td>0.186995</td>\n",
       "      <td>0.954963</td>\n",
       "      <td>0.256955</td>\n",
       "      <td>0.040860</td>\n",
       "      <td>0.228020</td>\n",
       "      <td>0.226395</td>\n",
       "      <td>0.149465</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.502086</td>\n",
       "      <td>0.797777</td>\n",
       "      <td>0.711036</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.419146</td>\n",
       "      <td>0.080673</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.781040</td>\n",
       "      <td>0.616331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.626213</td>\n",
       "      <td>0.196231</td>\n",
       "      <td>0.990585</td>\n",
       "      <td>0.396408</td>\n",
       "      <td>0.144086</td>\n",
       "      <td>0.320229</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>0.224355</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanfreq           sd       median          Q25          Q75  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.668412     0.399987     0.697887     0.567448     0.788722   \n",
       "std       0.141282     0.171832     0.145295     0.196990     0.102546   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.586978     0.243425     0.633838     0.448602     0.719235   \n",
       "50%       0.686980     0.420925     0.715516     0.566764     0.792710   \n",
       "75%       0.754545     0.502086     0.797777     0.711036     0.870690   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               IQR         skew         kurt       sp.ent          sfm  ...  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  ...   \n",
       "mean      0.293484     0.086701     0.026385     0.643020     0.460686  ...   \n",
       "std       0.180012     0.122616     0.103192     0.184838     0.220233  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.117820     0.043600     0.002754     0.506112     0.274377  ...   \n",
       "50%       0.335436     0.059432     0.004780     0.670306     0.445946  ...   \n",
       "75%       0.419146     0.080673     0.008857     0.781040     0.616331  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "          centroid      meanfun       minfun       maxfun      meandom  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.668412     0.479161     0.139093     0.884834     0.278452   \n",
       "std       0.141282     0.177428     0.098916     0.170873     0.178043   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.586978     0.337413     0.043478     0.857144     0.139672   \n",
       "50%       0.686980     0.466594     0.186995     0.954963     0.256955   \n",
       "75%       0.754545     0.626213     0.196231     0.990585     0.396408   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            mindom       maxdom      dfrange      modindx        label  \n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  \n",
       "mean      0.105184     0.230540     0.228653     0.186354     0.500000  \n",
       "std       0.139395     0.161082     0.161146     0.128119     0.500079  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.006452     0.094353     0.093616     0.107002     0.000000  \n",
       "50%       0.040860     0.228020     0.226395     0.149465     0.500000  \n",
       "75%       0.144086     0.320229     0.320100     0.224355     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "01c6142330ed1ac21db52dd832e8d14b4a51ec91"
   },
   "outputs": [],
   "source": [
    "X = voice.iloc[:, :-1]\n",
    "y = voice[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 20)\n",
      "(3168,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Các hàm và thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['female', 'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cost_curve(cost_values):\n",
    "    plt.plot(cost_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conclusion(model, cost=None):\n",
    "    start_time = time.time()\n",
    "    model.fit(X,y)\n",
    "    total_time = time.time() - start_time\n",
    "    y_pred=model.predict(X)\n",
    "    y_predll = (y_pred >= 0.5).astype(int)\n",
    "    if cost is None: cost = model.cost\n",
    "    print(classification_report(y, y_predll, target_names=target_names, digits=4))\n",
    "    print(\"===================\")\n",
    "    print(\"Mean loss: \", cost(y, y_pred))\n",
    "    print(\"Time for fitting: \", total_time)\n",
    "    print(\"===================\")\n",
    "    if hasattr(model, \"cost_values\"):\n",
    "        draw_cost_curve(model.cost_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Sử dụng phương pháp tối ưu Stochastic Average Gradient Descent từ thư viện Scikit-learn cho mô hình Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "19d364d29be43bc856b31f0ddec1d5a50a88e2c5"
   },
   "outputs": [],
   "source": [
    "model = SKLogisticRegression(penalty='none', tol=0.0001, solver='lbfgs', max_iter=100, verbose=0, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9765    0.9716    0.9741      1584\n",
      "        male     0.9717    0.9766    0.9742      1584\n",
      "\n",
      "    accuracy                         0.9741      3168\n",
      "   macro avg     0.9741    0.9741    0.9741      3168\n",
      "weighted avg     0.9741    0.9741    0.9741      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.8940074640994435\n",
      "Time for fitting:  0.031771183013916016\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hungvm/anaconda3/envs/common/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "conclusion(model, log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Tự xây dựng các thuật toán tối ưu Gradient Descent, Stochastic Gradient Descent và Mini Batch Gradient Descent cho mô hình Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.e**(-z))\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, optimizer, step_size, steps=100):\n",
    "        self.optimizer = optimizer\n",
    "        self.step_size = step_size\n",
    "        self.steps = steps\n",
    "        self.params = None\n",
    "        self.cost_values = list()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "        y = np.expand_dims(y, axis=1)\n",
    "        self.params = self.optimizer(X, y, self.step_size, self.steps, self.gradient, self.cost, self.cost_values)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "        y_pred = sigmoid(np.dot(X, self.params))\n",
    "        return np.squeeze(y_pred, axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def gradient(X, y_pred, y):\n",
    "        return 1/ y.shape[0] * np.dot(X.transpose(), (y_pred - y))\n",
    "\n",
    "    @staticmethod\n",
    "    def cost(y, y_pred):\n",
    "        return -1/y.shape[0] * np.squeeze(np.dot(y.transpose(), np.log(y_pred)) + np.dot((1 - y).transpose(), np.log(1 - y_pred)))[()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    step_numb = 0\n",
    "    while step_numb < steps:\n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        grad = gradient(X, y_pred, y)\n",
    "        params -= step_size * grad\n",
    "        cost_value = logreg_cost(y, y_pred)\n",
    "        cost_values.append(cost_value)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.7597    0.7923    0.7756      1584\n",
      "        male     0.7830    0.7494    0.7658      1584\n",
      "\n",
      "    accuracy                         0.7708      3168\n",
      "   macro avg     0.7713    0.7708    0.7707      3168\n",
      "weighted avg     0.7713    0.7708    0.7707      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.5768001864620869\n",
      "Time for fitting:  0.04777789115905762\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_gd = LogisticRegression(gradient_descent, 10**-1, 100)\n",
    "conclusion(logreg_with_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochactis Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values):\n",
    "    N = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "#     params = np.random.randn(d, 1)\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    step_numb = 0\n",
    "    \n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    cost_values.append(logreg_cost(y, y_pred))\n",
    "    \n",
    "    check_w_after = 5\n",
    "    tol = 1e-3\n",
    "    while step_numb < steps:\n",
    "        # shuffle data after every step\n",
    "        shuffled_idxs = np.random.permutation(N)\n",
    "        for i in shuffled_idxs:\n",
    "            curr_X = np.expand_dims(X[i], axis=0)\n",
    "            curr_y = y[i]\n",
    "            curr_y_pred = sigmoid(np.dot(curr_X, params))\n",
    "            \n",
    "            # calculate gradient with current datapoint\n",
    "            grad = gradient(curr_X, curr_y_pred, curr_y)\n",
    "            \n",
    "            # update params\n",
    "            params -= step_size * grad\n",
    "            \n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        cost_value = logreg_cost(y, y_pred)\n",
    "        \n",
    "        cost_values.append(cost_value)\n",
    "        \n",
    "        # stop using tolerance criteria\n",
    "        if step_numb % check_w_after == 0 and cost_value < tol: \n",
    "            print(\"Total steps: \", step_numb)\n",
    "            break\n",
    "            \n",
    "        # step size decays\n",
    "        step_size /= 2    \n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9774    0.9552    0.9662      1584\n",
      "        male     0.9562    0.9779    0.9669      1584\n",
      "\n",
      "    accuracy                         0.9665      3168\n",
      "   macro avg     0.9668    0.9665    0.9665      3168\n",
      "weighted avg     0.9668    0.9665    0.9665      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.1515124632207481\n",
      "Time for fitting:  11.653931856155396\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_sgd = LogisticRegression(stochastic_gradient_descent, 10**-1, 100)\n",
    "conclusion(logreg_with_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradient_descent(X, y, step_size, steps, gradient, logreg_cost, cost_values, batch_size=64):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    number_of_batches = y.shape[0] // batch_size + (0 if y.shape[0] % batch_size == 0 else 1)\n",
    "    print(\"Number of batches: \", number_of_batches)\n",
    "    step_numb = 0\n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    cost_values.append(logreg_cost(y, y_pred))\n",
    "    while step_numb < steps:\n",
    "        curr_batch = 0\n",
    "        # shuffle data after every step\n",
    "        X_train, y_train = shuffle(X, y)\n",
    "        while curr_batch < number_of_batches:\n",
    "            # select mini batch from dataset\n",
    "            start_range = batch_size*curr_batch\n",
    "            end_range = batch_size*(curr_batch + 1)\n",
    "            mini_X = X_train[start_range: end_range]\n",
    "            mini_y = y_train[start_range: end_range]\n",
    "            \n",
    "            mini_y_pred = sigmoid(np.dot(mini_X, params))\n",
    "            \n",
    "            # calculate gradient with current mini batch\n",
    "            grad = gradient(mini_X, mini_y_pred, mini_y)\n",
    "            \n",
    "            # update params\n",
    "            params -= step_size * grad\n",
    "            curr_batch += 1\n",
    "            \n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        cost_value = logreg_cost(y, y_pred)\n",
    "        cost_values.append(cost_value)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.9749    0.9545    0.9646      1584\n",
      "        male     0.9555    0.9754    0.9653      1584\n",
      "\n",
      "    accuracy                         0.9650      3168\n",
      "   macro avg     0.9652    0.9650    0.9650      3168\n",
      "weighted avg     0.9652    0.9650    0.9650      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.16863727837465886\n",
      "Time for fitting:  0.2840440273284912\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_mbgd = LogisticRegression(mini_batch_gradient_descent, 10**-1, 100)\n",
    "conclusion(logreg_with_mbgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Áp dụng backtracking (1 ví dụ cho thuật toán Gradient Descent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_with_backtracking(X, y, step_size_init, steps, gradient, logreg_cost, cost_values, alpha=0.5, beta=0.5):\n",
    "    params = np.ones((X.shape[1], 1))\n",
    "    y_pred = sigmoid(np.dot(X, params))\n",
    "    step_numb = 0\n",
    "    prev_cost = None\n",
    "    cost = logreg_cost(y, y_pred)\n",
    "    cost_values.append(cost)\n",
    "    max_step_inside = 20\n",
    "    while step_numb < steps:\n",
    "        step_size = step_size_init\n",
    "        prev_cost = cost\n",
    "        grad = gradient(X, y_pred, y)\n",
    "        params -= step_size * grad\n",
    "        y_pred = sigmoid(np.dot(X, params))\n",
    "        cost = logreg_cost(y, y_pred)\n",
    "        grad_norm = np.linalg.norm(grad)\n",
    "        step_inside = 0\n",
    "        while step_inside < max_step_inside and cost > prev_cost - alpha * step_size * grad_norm**2:\n",
    "            step_size *= beta\n",
    "            step_inside += 1\n",
    "        cost_values.append(cost)\n",
    "        step_numb += 1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female     0.7597    0.7923    0.7756      1584\n",
      "        male     0.7830    0.7494    0.7658      1584\n",
      "\n",
      "    accuracy                         0.7708      3168\n",
      "   macro avg     0.7713    0.7708    0.7707      3168\n",
      "weighted avg     0.7713    0.7708    0.7707      3168\n",
      "\n",
      "===================\n",
      "Mean loss:  0.5768001864620869\n",
      "Time for fitting:  0.04967975616455078\n",
      "===================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_with_gd_bt = LogisticRegression(gradient_descent_with_backtracking, 10**-1, 100)\n",
    "conclusion(logreg_with_gd_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:common]",
   "language": "python",
   "name": "conda-env-common-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
